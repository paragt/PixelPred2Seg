#!/usr/bin/env python

import os
import sys
import pdb
#pdb.set_trace()
this_dir = os.path.realpath(os.path.dirname(sys.argv[0]))
pkg_dir = os.path.realpath(os.path.join(this_dir, 'segeval'))
#pkg_dir = os.path.realpath(os.path.join(p_dir, '..'))
sys.path.insert(0, pkg_dir)

from numpy import *
import imio
import evaluate as ev
import morpho
from scipy.ndimage import binary_dilation, generate_binary_structure
import getopt
import errno
import json
import argparse


larva_gt='/groups/flyem/proj/data/larva_fib_groundtruth_round2.h5'
medulla_gt='/groups/flyem/proj/data/larva_fib_groundtruth_round2.h5'

class Error(Exception):
    """Base-class for exceptions in this module."""

class UsageError(Error):
    def __init__(self, msg):
        self.msg = msg

if __name__ == "__main__" :
#def main(argv):
    parser = argparse.ArgumentParser(description='Perform VI accuracy comparison between two stacks')
    parser.add_argument('--stack1', type=str, help='Stack compared against base stack (stack path or h5)', dest='stack1', required=True)
    parser.add_argument('--stackbase', type=str, help='Base stack (stack path or h5)', dest='stackbase', required=True)
    parser.add_argument('--synapsejson', type=str, help='JSON file with synapse annotations', dest='synapsejson', default='')
    
    parser.add_argument('--relabel1', action='store_true', default=False, help='Relabel ids in stack 1 to prevent memory issues', dest='relabel1')
    parser.add_argument('--relabelbase', action='store_true', default=False, help='Relabel ids in stack base to prevent memory issues', dest='relabelbase')
    parser.add_argument('--anisotropic', action='store_true', default=False, help='Modify strel for anisotropy', dest='anisotropic')
    parser.add_argument('--filtersize', type=int, default=1000, help='Size below which comparisons are not made', dest='filtersize')
    parser.add_argument('--VIthres', type=float, default=0.02, help='VI difference below which is unimportant', dest='VIthres')
    parser.add_argument('--stack1_outjson', type=str, default='stack1_merged.json', help='output json file name for stack 1 (outputs over-merged bodies in stack 1)', dest='stack1_outjson')
    parser.add_argument('--stackbase_outjson', type=str, default='stackbase_merged.json', help='output json file name for stack base (outputs over-merged bodies in stack base)', dest='stackbase_outjson')

    parser.add_argument('--dilate1', type=int, default=0, help='Create and dilate edges on stack 1', dest='dilate1')
    parser.add_argument('--dilatebase', type=int, default=0, help='Create and dilate edges on base image', dest='dilatebase')

    args = parser.parse_args()


    filtersize = args.filtersize
    if args.synapsejson != '':
        filtersize = 0

    stack1=args.stack1
    stack1_int = None
    if stack1.endswith('.h5'):
        stack1_int = imio.read_image_stack(stack1)
    else: 
        stack1_int = imio.raveler_to_labeled_volume(stack1, glia=False, use_watershed=False)
    stack1_int = morpho.remove_small_connected_components(stack1_int, min_size=filtersize, in_place=True)
    
    #pdb.set_trace()
    
    if args.dilate1 > 0:
        conn = 1 # the connectivity, can be in {1, 2, ..., seg.ndim}
        bound = morpho.seg_to_bdry(stack1_int)
        strel = generate_binary_structure(stack1_int.ndim, conn)
        if args.anisotropic==True:
            strel[0,1,1]=False
            strel[2,1,1]=False
        
        bound = binary_dilation(bound, strel, iterations=args.dilate1)
        stack1_int[bound] = 0
    #pdb.set_trace()
    if args.relabel1:
        stack1_int, dummy1, dummy2 = ev.relabel_from_one(stack1_int)
    print "Imported first stack with "+ str(unique(stack1_int).size) + " regions"


    #pdb.set_trace()    
    stackbase=args.stackbase
    stackbase_int = None
    if stackbase.endswith('.h5'):
        stackbase_int = imio.read_image_stack(stackbase)
    else:
        stackbase_int = imio.raveler_to_labeled_volume(stackbase, glia=False, use_watershed=False)
    stackbase_int = morpho.remove_small_connected_components(stackbase_int, min_size=filtersize, in_place=True)

    #pdb.set_trace()
    
    if args.dilatebase > 0:
        conn = 1 # the connectivity, can be in {1, 2, ..., seg.ndim}
        bound = morpho.seg_to_bdry(stackbase_int)
        strel = generate_binary_structure(stackbase_int.ndim, conn)        
        if args.anisotropic==True:
            strel[0,1,1]=False
            strel[2,1,1]=False
        bound = binary_dilation(bound, strel, iterations=args.dilatebase)
        stackbase_int[bound] = 0

    if args.relabelbase:
        stackbase_int, dummy1, dummy2 = ev.relabel_from_one(stackbase_int)
    print "Imported base stack with "+ str(unique(stackbase_int).size) + " regions"
    
    merge = None
    split = None
    stack1_bodies = None
    stack1_vis = None
    gt_bodies = None
    gt_vis = None

    if args.synapsejson != '':
        synaptic_vi, synaptic_comps = ev.make_synaptic_functions(args.synapsejson, [ev.split_vi, ev.sorted_vi_components])
        merge, split = synaptic_vi(stack1_int, stackbase_int)
        print "SynMergeSplit: " + str((merge, split))
        stack1_bodies, stack1_vis, gt_bodies, gt_vis = synaptic_comps(stack1_int, stackbase_int)
    else:
        merge, split = ev.split_vi(stack1_int, stackbase_int)
        print str(merge) + ',' + str(split)
        #print "MergeSplit: " + str((merge, split))

    RI, ss, ds, sd, dd  = ev.rand_index(stack1_int, stackbase_int)
    print str(1e5*ds/(ss+dd+ds+sd))+ ',' + str(1e5*sd/(ss+dd+ds+sd))
    #print "RAND Merge Split: " + str((RI, 1e5*ds/(ss+dd+ds+sd), 1e5*sd/(ss+dd+ds+sd)))

   #data=[]
   #database=[]

   #stack1_fp = open(args.stack1_outjson, "w")
   #stackbase_fp = open(args.stackbase_outjson, "w")

   #i=0
   #accum = 0

   #if merge > args.VIthres:
       #for bodyid in stack1_bodies:
           #if accum > (merge - args.VIthres):
               #break        
           #accum += stack1_vis[i]
           #i += 1
           #data.append({'status' : 'not sure', 'body ID' : int(bodyid), 'vi contrib' : stack1_vis[i-1]})    

   #i=0
   #accum = 0
   #if split > args.VIthres:
       #for bodyid in gt_bodies:
           #if accum > (split - args.VIthres):
               #break        
           #accum += gt_vis[i]
           #i += 1
           #database.append({'status' : 'not sure', 'body ID' : int(bodyid), 'vi contrib' : gt_vis[i-1]})    

   #json_out_data = {'data' : data}
   #json_out_data2 = {'data' : database}

   #stack1_fp.write(json.dumps(json_out_data, sort_keys=False, indent=2)) 
   #stackbase_fp.write(json.dumps(json_out_data2, sort_keys=False, indent=2)) 

#sys.exit(main(sys.argv))
